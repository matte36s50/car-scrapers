name: BAT and CNB Scraper Pipeline

on:
  schedule:
    - cron: '0 6 * * *'   # 6 AM UTC daily
    - cron: '0 18 * * *'  # 6 PM UTC daily
  workflow_dispatch:      # Allow manual trigger

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        fetch-depth: 1
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install playwright==1.40.0
        pip install beautifulsoup4==4.12.2
        pip install pandas==2.1.4
        pip install boto3==1.34.0
        pip install lxml==4.9.3
        pip install requests==2.31.0
        pip install numpy==1.24.4
    
    - name: Install Playwright browsers
      run: |
        python -m playwright install chromium
        python -m playwright install-deps chromium
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Test S3 connection
      run: |
        echo "Testing S3 connection to my-mii-reports bucket..."
        aws s3 ls s3://my-mii-reports/ --max-items 5 || echo "S3 connection test completed"
    
    - name: Run BAT scraper
      run: |
        echo "Starting BAT scraper..."
        python bat_scraper.py
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
    
    - name: Run CNB scraper
      if: success()
      run: |
        echo "Starting CNB scraper..."
        python cnb_scraper.py || echo "CNB scraper completed with issues"
      continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
    
    - name: Run MII calculator
      if: success()
      run: |
        echo "Starting MII calculator..."
        python enhanced_mii_all_models.py || echo "MII calculator completed"
      continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
    
    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-outputs-${{ github.run_number }}
        path: |
          *.csv
          *.json
          *.log
        retention-days: 7
        if-no-files-found: warn
    
    - name: Check outputs
      if: always()
      run: |
        echo "Checking generated files:"
        ls -la *.csv 2>/dev/null || echo "No CSV files"
        ls -la *.json 2>/dev/null || echo "No JSON files"
