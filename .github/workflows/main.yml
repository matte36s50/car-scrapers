name: BAT and CNB Scraper Pipeline

on:
  schedule:
    - cron: '0 6 * * *'   # 6 AM UTC
    - cron: '0 18 * * *'  # 6 PM UTC
  workflow_dispatch:

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip list
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Test AWS S3 connection
      run: |
        echo "Testing S3 connection..."
        aws s3 ls s3://my-mii-reports/ --max-items 5 || echo "S3 test failed"
    
    - name: Run BAT scraper
      run: python bat_scraper.py
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    
    - name: Run CNB scraper
      run: python cnb_scraper.py
      continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    
    - name: Run MII Calculator
      run: python enhanced_mii_all_models.py
      continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    
    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-outputs-${{ github.run_number }}
        path: |
          *.csv
          *.log
        retention-days: 7
        if-no-files-found: warn
